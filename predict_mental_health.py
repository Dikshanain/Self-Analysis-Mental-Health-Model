# -*- coding: utf-8 -*-
"""Self-Analysis_Mental_Health_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IEADT17P39kKiSXNU0q7BXVX51KBAx9D

**Objective**

Develop a Self-Analysis Mental Health Model that predicts possible mental health conditions based on user-provided symptoms. The model should be designed for seamless integration into a chatbot or an application, with a focus on accuracy, interpretability, and efficiency. Additionally, a basic UI or command-line script should be provided for testing and interaction.
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive

"""**Initial Observations:**

The dataset has 1,259 rows and 27 columns.
The "Timestamp" column is not needed for modeling.
Missing values are present in columns like "state" (41% missing), "self_employed" (1.4%), "work_interfere" (21%), and "comments" (87%).
The dataset contains both numerical and categorical data.
The "Age" column might have outliers (e.g., extremely high or low values).
The "comments" column is mostly empty and may not be useful.

**Next Steps:**

Remove unnecessary columns: Drop "Timestamp" and "comments".
Handle missing values: Impute or drop missing data.
Normalize categorical data: Standardize gender labels.
EDA: Analyze age distribution, relationships between symptoms, and mental health conditions.
Feature Engineering & Selection: Encode categorical variables and choose relevant features.
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler

# Load the dataset
file_path = "survey.csv"  # Update the path if needed
df = pd.read_csv(file_path)

"""# **Data Preparation**"""

### STEP 1: DATA CLEANING ###

# Drop unnecessary columns
df.drop(columns=["Timestamp", "comments"], inplace=True, errors="ignore")

# Standardize Gender labels
df["Gender"] = df["Gender"].str.lower().str.strip()
gender_map = {
    "male": "Male", "m": "Male", "man": "Male",
    "female": "Female", "f": "Female", "woman": "Female",
    "non-binary": "Other", "nb": "Other", "genderqueer": "Other", "agender": "Other"
}
df["Gender"] = df["Gender"].replace(gender_map)

# Remove age outliers (keeping values between 18-100)
df = df[(df["Age"] >= 18) & (df["Age"] <= 100)]

# Drop "state" column as it has too many missing values
df.drop(columns=["state"], inplace=True, errors="ignore")

### STEP 2: HANDLE MISSING VALUES ###

# Fill missing values in "self_employed" with "No"
df["self_employed"].fillna("No", inplace=True)

# Fill missing values in "work_interfere" with "Don't know"
df["work_interfere"].fillna("Don't know", inplace=True)

### STEP 3 : NORMALIZATION ###
# Initialize MinMaxScaler
scaler = MinMaxScaler()

# Normalize Age column
df["Age"] = scaler.fit_transform(df[["Age"]])

# Save cleaned dataset with normalization
df.to_csv("survey_cleaned_normalized.csv", index=False)

print("Normalization Complete! Cleaned & normalized dataset saved as 'survey_cleaned_normalized.csv'.")
df.head()

from sklearn.preprocessing import LabelEncoder

# Initialize the label encoder
label_encoders = {}

# Loop through all columns and apply encoding for categorical columns
for col in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le  # Store the encoder for later use

# Check the dataset after encoding
print(df.head())

### STEP 4: EXPLORATORY DATA ANALYSIS (EDA) ###

# Set Seaborn style
sns.set_style("whitegrid")

# Plot Age Distribution
plt.figure(figsize=(8, 5))
sns.histplot(df["Age"], bins=20, kde=True, color="blue")
plt.title("Age Distribution")
plt.xlabel("Age")
plt.ylabel("Count")
plt.show()

# Gender Distribution
plt.figure(figsize=(6, 4))
sns.countplot(x="Gender", data=df, palette="pastel")
plt.title("Gender Distribution")
plt.xlabel("Gender")
plt.ylabel("Count")
plt.show()

# Family History vs. Seeking Treatment
plt.figure(figsize=(6, 4))
sns.countplot(x="family_history", hue="treatment", data=df, palette="coolwarm")
plt.title("Family History vs. Seeking Treatment")
plt.xlabel("Family History of Mental Illness")
plt.ylabel("Count")
plt.legend(title="Treatment Sought")
plt.show()

### STEP 5: FEATURE ENGINEERING & SELECTION ###

# Encode categorical features
label_encoders = {}
for column in df.select_dtypes(include=["object"]).columns:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    label_encoders[column] = le  # Store encoders for future decoding

# Save the cleaned dataset
df.to_csv("survey_cleaned.csv", index=False)

# Display transformed dataset
print("Data Preparation Complete! Cleaned dataset saved as 'survey_cleaned.csv'.")
df.head()

"""# **Model Development**"""

import pandas as pd
from sklearn.model_selection import train_test_split


# Print available columns to confirm which ones exist
print("Dataset Columns:", df.columns)

# Define Features (X) and Target (y)
drop_columns = ['treatment', 'Timestamp', 'comments', 'Country']

# Drop only the columns that exist in the dataset
X = df.drop(columns=[col for col in drop_columns if col in df.columns])

# Define Target Variable
y = df['treatment']  # Ensure 'treatment' exists in the dataset

# Train-test split (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Verify data shapes
print("Shape of X:", X.shape)
print("Shape of y:", y.shape)
print("First few rows of X:\n", X.head())
print("First few rows of y:\n", y.head())

from sklearn.preprocessing import OneHotEncoder
from sklearn.cluster import KMeans
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report
import shap
import joblib

# Define mental health condition labels using K-Means clustering
mental_health_features = ["family_history", "work_interfere", "mental_health_consequence", "seek_help", "benefits", "leave", "care_options", "mental_vs_physical", "treatment"]
X_labels = df[mental_health_features]

# Apply K-Means clustering to create mental health condition labels
kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)
df["mental_health_condition"] = kmeans.fit_predict(X_labels)

# Define features (X) and new target (y)
X = df.drop(columns=["mental_health_condition"])
y = df["mental_health_condition"]

# One-hot encode target labels for multi-class ROC-AUC
onehot = OneHotEncoder()
y_onehot = onehot.fit_transform(y.values.reshape(-1, 1)).toarray()

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
y_test_onehot = onehot.transform(y_test.values.reshape(-1, 1)).toarray()

# Define models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "XGBoost": XGBClassifier(eval_metric="mlogloss", random_state=42)
}

# Train and evaluate each model
results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)

    # Compute evaluation metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    roc_auc = roc_auc_score(y_test_onehot, y_pred_proba, multi_class='ovr')

    results[name] = {
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1-score": f1,
        "ROC-AUC": roc_auc
    }

# Print results
print("Model Performance Comparison:")
for model, metrics in results.items():
    print(f"\n{model}:")
    for metric, value in metrics.items():
        print(f"  {metric}: {value:.4f}")

# Select the best model (highest F1-score)
best_model_name = max(results, key=lambda x: results[x]["F1-score"])
best_model = models[best_model_name]

# Save the best model
joblib.dump(best_model, "mental_health_model.pkl")

# SHAP Interpretation
explainer = shap.Explainer(best_model, X_train)
shap_values = explainer(X_test)
shap.summary_plot(shap_values.values, X_test)

!pip install gradio shap joblib matplotlib pandas

import joblib
import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Load your dataset (modify the filename accordingly)
df = pd.read_csv("survey_cleaned_normalized.csv")  # Update this with your actual dataset file

# Identify categorical columns that need encoding
categorical_features = ["Gender", "work_interfere", "family_history", "benefits", "care_options", "anonymity", "leave"]  # Modify as per your dataset

# Train LabelEncoders
label_encoders = {col: LabelEncoder().fit(df[col]) for col in categorical_features}

# Save encoders to a file
joblib.dump(label_encoders, "label_encoders.pkl")

print("âœ… label_encoders.pkl has been created successfully!")

"""# **Basic Command-Line Testing**"""

import joblib
import pandas as pd

# Load trained model and encoders
model = joblib.load("mental_health_model.pkl")
label_encoders = joblib.load("label_encoders.pkl")

# Min and Max age values from original dataset (used during normalization)
AGE_MIN, AGE_MAX = 18, 100

# Human-readable labels for the conditions
condition_labels = ["Depression", "Anxiety", "Bipolar Disorder"]

def preprocess_input(user_input):
    """Preprocess user input to match the model's expected feature set."""
    df = pd.DataFrame([user_input])

    # Encode categorical values
    for col, le in label_encoders.items():
        if col in df.columns:
            df[col] = le.transform(df[col])

    # Normalize 'Age' column manually
    if "Age" in df.columns:
        df["Age"] = (df["Age"] - AGE_MIN) / (AGE_MAX - AGE_MIN)

    # Add missing columns with default values and reorder columns
    expected_features = model.feature_names_in_
    missing_cols = set(expected_features) - set(df.columns)

    for col in missing_cols:
        df[col] = 0  # Default value for missing features

    df = df[expected_features]  # Reorder columns as per model requirements
    return df

def predict_mental_health(age, gender, work_interference, family_history, benefits, care_options, anonymity, leave):
    """Predict mental health condition and provide explanations."""
    user_input = {
        "Age": age,
        "Gender": gender,  # Ensure gender is a string, not a list
        "work_interfere": work_interference,  # Same for other categorical variables
        "family_history": family_history,
        "benefits": benefits,
        "care_options": care_options,
        "anonymity": anonymity,
        "leave": leave
    }

    processed_input = preprocess_input(user_input)
    prediction = model.predict(processed_input)[0]

    # Check if the prediction is within the valid range
    if prediction < 0 or prediction >= len(condition_labels):
        prediction = 0  # Default to "Depression" if prediction is out of range

    # Map condition to coping strategy
    coping_strategies = {
        "Depression": "Try regular exercise, therapy, and social support.",
        "Anxiety": "Practice mindfulness, deep breathing, and cognitive behavioral therapy.",
        "Bipolar Disorder": "Maintain a consistent routine, take prescribed medications, and seek counseling.",
    }

    # Map prediction to a human-readable condition
    condition = condition_labels[prediction]
    strategy = coping_strategies.get(condition, "Consider consulting a mental health professional.")

    return condition, strategy

if __name__ == "__main__":
    # Command-line user inputs
    age = float(input("Enter age: "))
    gender = input("Enter gender (Male/Female/Other): ")
    work_interference = input("Enter work interference (Often/Rarely/Never): ")
    family_history = input("Do you have family history of mental illness? (Yes/No): ")
    benefits = input("Does your company offer mental health benefits? (Yes/No): ")
    care_options = input("Do you have access to care options? (Yes/No): ")
    anonymity = input("Do you prefer anonymity? (Yes/No): ")
    leave = input("How easy is it to take mental health leave? (Very easy/Somewhat easy/Somewhat difficult/Very difficult): ")

    # Get prediction and strategy
    condition, strategy = predict_mental_health(age, gender, work_interference, family_history, benefits, care_options, anonymity, leave)

    # Output the result
    print(f"\nPredicted Mental Health Condition: {condition}")
    print(f"Coping Strategy: {strategy}")
